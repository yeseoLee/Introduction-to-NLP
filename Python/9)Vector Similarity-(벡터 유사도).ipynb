{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벡터 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 코사인 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity = cos(세타) = A•B / ||A|| ||B||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "#코사인 유사도 계산\n",
    "def cos_sim(A: np.array ,B: np.array):\n",
    "    return dot(A,B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서1 : 저는 사과 좋아요  \n",
    "문서2 : 저는 바나나 좋아요  \n",
    "문서3 : 저는 바나나 좋아요 저는 바나나 좋아요  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['바나나', '사과', '저는', '좋아요']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "docs = [\n",
    "  '저는 사과 좋아요',\n",
    "  '저는 바나나 좋아요',\n",
    "  '저는 바나나 좋아요 저는 바나나 좋아요'\n",
    "] \n",
    "#전체 단어 집합 생성\n",
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "vocab.sort()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>문서1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     바나나  사과  저는  좋아요\n",
       "문서1    0   1   1    1\n",
       "문서2    1   0   1    1\n",
       "문서3    2   0   2    2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DTM 구하기\n",
    "DTM=[]\n",
    "for doc in docs:\n",
    "    vector=[]\n",
    "    for voca in vocab:\n",
    "        #각 단어에 대해 문장에서 몇번 등장하는지 계산(TF)\n",
    "        vector.append(doc.count(voca))\n",
    "    DTM.append(vector)\n",
    "df = pd.DataFrame(DTM,['문서1','문서2','문서3'],columns= vocab)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=DTM[0]\n",
    "doc2=DTM[1]\n",
    "doc3=DTM[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n",
      "0.6666666666666667\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim(doc1, doc2)) #문서1과 문서2의 코사인 유사도\n",
    "print(cos_sim(doc1, doc3)) #문서1과 문서3의 코사인 유사도\n",
    "print(cos_sim(doc2, doc3)) #문서2과 문서3의 코사인 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cos_sim(1,2)와 cos_sim(1,3)의 유사도가 같음  \n",
    "-> 문서의 길이가 다른 상황에서도 공정한 비교 가능  \n",
    "벡터의 크기가 아닌, 방향(패턴)에 초점을 두기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코사인 유사도를 이용한 추천 시스템 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "\n",
       "                               homepage    id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story   862  tt0114709                en   \n",
       "1                                   NaN  8844  tt0113497                en   \n",
       "\n",
       "  original_title                                           overview  ...  \\\n",
       "0      Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1        Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "\n",
       "  release_date      revenue runtime  \\\n",
       "0   1995-10-30  373554033.0    81.0   \n",
       "1   1995-12-15  262797249.0   104.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "\n",
       "                                     tagline      title  video vote_average  \\\n",
       "0                                        NaN  Toy Story  False          7.7   \n",
       "1  Roll the dice and unleash the excitement!    Jumanji  False          6.9   \n",
       "\n",
       "  vote_count  \n",
       "0     5415.0  \n",
       "1     2413.0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/movies_metadata.csv', low_memory=False)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상위 20000개의 데이터 사용\n",
    "data = data.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NULL값 확인\n",
    "data['overview'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview에서 Null값 제거(빈 값(empty value)으로 대체)\n",
    "data['overview'] = data['overview'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 47487)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "# overview에 대해서 tf-idf 수행\n",
    "tfidf_matrix = tfidf.fit_transform(data['overview'])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코사인 유사도 구하기\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Toy Story                      0\n",
      "Jumanji                        1\n",
      "Grumpier Old Men               2\n",
      "Waiting to Exhale              3\n",
      "Father of the Bride Part II    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#타이틀과 인덱스를 갖는 테이블 생성\n",
    "indices = pd.Series(data.index, index=data['title']).drop_duplicates()\n",
    "print(indices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "idx = indices['Father of the Bride Part II']\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 overview가 비슷한 10개의 영화를 찾아내는 함수\n",
    "def get_recommendations(title: str, cosine_sim = cosine_sim):\n",
    "    #선택한 영화의 인덱스를 받아옵니다.\n",
    "    idx = indices[title]\n",
    "    \n",
    "    #모든 영화에 대해 해당 영화와의 유사도 구하기\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    #유사도에 따라 영화들을 정렬\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    #가장 유사한 10개의 영화 선택하고 인덱스 받아오기\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    #제목 리턴\n",
    "    return data['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12481                            The Dark Knight\n",
       "150                               Batman Forever\n",
       "1328                              Batman Returns\n",
       "15511                 Batman: Under the Red Hood\n",
       "585                                       Batman\n",
       "9230          Batman Beyond: Return of the Joker\n",
       "18035                           Batman: Year One\n",
       "19792    Batman: The Dark Knight Returns, Part 1\n",
       "3095                Batman: Mask of the Phantasm\n",
       "10122                              Batman Begins\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Dark Knight Rises')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 유클리드 거리(Euclidean distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 점 사이의 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dist(x,y):   \n",
    "    return np.sqrt(np.sum((x-y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=DTM[0]\n",
    "doc2=DTM[1]\n",
    "doc3=DTM[2]\n",
    "docQ = np.array((1,1,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "1.4142135623730951\n",
      "2.6457513110645907\n"
     ]
    }
   ],
   "source": [
    "print(dist(doc1,docQ))\n",
    "print(dist(doc2,docQ))\n",
    "print(dist(doc3,docQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "값이 작을수록 거리가 가깝다 -> 유사하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 자카드 유사도(Jaccard similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J(A,B) = |AnB| / |AuB| (합집합에서 교집합의 비율, 동일하면 1, 전부 다르면 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'everyone', 'like', 'likey', 'watch', 'card', 'holder']\n",
      "['apple', 'banana', 'coupon', 'passport', 'love', 'you']\n"
     ]
    }
   ],
   "source": [
    "# 다음과 같은 두 개의 문서가 있습니다.\n",
    "# 두 문서 모두에서 등장한 단어는 apple과 banana 2개.\n",
    "doc1 = \"apple banana everyone like likey watch card holder\"\n",
    "doc2 = \"apple banana coupon passport love you\"\n",
    "\n",
    "# 토큰화\n",
    "tokenized_doc1 = doc1.split()\n",
    "tokenized_doc2 = doc2.split()\n",
    "print(tokenized_doc1)\n",
    "print(tokenized_doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 {'like', 'passport', 'everyone', 'love', 'card', 'you', 'banana', 'coupon', 'watch', 'likey', 'holder', 'apple'}\n"
     ]
    }
   ],
   "source": [
    "#합집합\n",
    "union = set(tokenized_doc1).union(set(tokenized_doc2))\n",
    "print(len(union),union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 {'banana', 'apple'}\n"
     ]
    }
   ],
   "source": [
    "#교집합\n",
    "intersection = set(tokenized_doc1).intersection(set(tokenized_doc2))\n",
    "print(len(intersection),intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(len(intersection)/len(union))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 레벤슈타인 거리(Levenshtein Distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레벨슈타인 거리: 문자열이 얼마나 비슷한지를 나타내는 것으로 편집거리라고도 부른다.  \n",
    "ex) hat -> here (편집거리3)  \n",
    "a -> e  \n",
    "t -> r  \n",
    "  -> e (+e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#레벨슈타인 거리 구하기\n",
    "def calc_distance(a: str , b: str):\n",
    "    if a==b: return 0\n",
    "    a_len=len(a)\n",
    "    b_len=len(b)\n",
    "    if a==\"\" : return b_len\n",
    "    if b==\"\" : return a_len\n",
    "\n",
    "    #2차원 매트릭스 (a_len+1, b_len+1)\n",
    "    matrix=[[0 for j in range(b_len+1)] for i in range(a_len+1)]\n",
    "\n",
    "    #첫 번째 행, 첫 번째 열을  문자열 길이로 초기화\n",
    "    for i in range(a_len+1):\n",
    "        matrix[i][0]=i\n",
    "    for j in range(b_len+1):\n",
    "        matrix[0][j]=j\n",
    "\n",
    "    for i in range(1, a_len+1):\n",
    "        ac=a[i-1] #비교할 문자\n",
    "        for j in range(1, b_len+1):\n",
    "            bc=b[j-1] #비교할 문자\n",
    "            cost = 0 if (ac==bc) else 1 #같으면 비용 0, 다르면 비용 1\n",
    "            matrix[i][j]=min([\n",
    "                matrix[i-1][j]+1, #문자 삽입\n",
    "                matrix[i][j-1]+1, #문자 제거\n",
    "                matrix[i-1][j-1]+cost #문자 변경\n",
    "            ])\n",
    "\n",
    "    return matrix[a_len][b_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 신촌역\n",
      "1 신천역\n",
      "2 신천군\n",
      "2 신발\n",
      "2 마곡역\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "samples = [\"신촌역\",\"신천군\",\"신천역\",\"신발\",\"마곡역\"]\n",
    "base = samples[0]\n",
    "r = sorted(samples, key = lambda x : calc_distance(base,x))\n",
    "for x in r:\n",
    "    print(calc_distance(base,x),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2, debug=False):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1, debug)\n",
    "\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 #문자 삽입\n",
    "            deletions = current_row[j] + 1 #문자 제거\n",
    "            substitutions = previous_row[j] + (c1 != c2) #문자 변경\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "\n",
    "        if debug:\n",
    "            print(current_row[1:])\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[2, 2, 3, 4, 5]\n",
      "[3, 3, 3, 4, 5]\n",
      "[4, 4, 4, 4, 5]\n",
      "[4, 5, 5, 4, 5]\n",
      "[5, 4, 5, 5, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '꿈을꾸는아이'\n",
    "s2 = '아이오아이'\n",
    "levenshtein(s1, s2, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글처럼 한 글자가 요소들로 이루어진 언어에 적합한 방식인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "s1 = '서비스'\n",
    "s2 = '써비스'\n",
    "s3 = '자비스'\n",
    "\n",
    "s4 = '밥 먹어'\n",
    "s5 = '밥 먹엉'\n",
    "s6 = '너 먹어'\n",
    "\n",
    "print(levenshtein(s1,s2),levenshtein(s1,s3))\n",
    "print(levenshtein(s4,s5),levenshtein(s4,s6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 텍스트 초성/중성/종성 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_begin = 44032\n",
    "kor_end = 55203\n",
    "chosung_base = 588\n",
    "jungsung_base = 28\n",
    "jaum_begin = 12593\n",
    "jaum_end = 12622\n",
    "moum_begin = 12623\n",
    "moum_end = 12643\n",
    "\n",
    "chosung_list = [ 'ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', \n",
    "        'ㅅ', 'ㅆ', 'ㅇ' , 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "jungsung_list = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', \n",
    "        'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', \n",
    "        'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', \n",
    "        'ㅡ', 'ㅢ', 'ㅣ']\n",
    "\n",
    "jongsung_list = [\n",
    "    ' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ',\n",
    "        'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', \n",
    "        'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', \n",
    "        'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "jaum_list = ['ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄸ', 'ㄹ', \n",
    "              'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', \n",
    "              'ㅃ', 'ㅄ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "\n",
    "moum_list = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', \n",
    "              'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "\n",
    "def compose(chosung, jungsung, jongsung):\n",
    "    char = chr(\n",
    "        kor_begin +\n",
    "        chosung_base * chosung_list.index(chosung) +\n",
    "        jungsung_base * jungsung_list.index(jungsung) +\n",
    "        jongsung_list.index(jongsung)\n",
    "    )\n",
    "    return char\n",
    "\n",
    "def decompose(c):\n",
    "    if not character_is_korean(c):\n",
    "        return None\n",
    "    i = ord(c)\n",
    "    if (jaum_begin <= i <= jaum_end):\n",
    "        return (c, ' ', ' ')\n",
    "    if (moum_begin <= i <= moum_end):\n",
    "        return (' ', c, ' ')\n",
    "\n",
    "    # decomposition rule\n",
    "    i -= kor_begin\n",
    "    cho  = i // chosung_base\n",
    "    jung = ( i - cho * chosung_base ) // jungsung_base \n",
    "    jong = ( i - cho * chosung_base - jung * jungsung_base )    \n",
    "    return (chosung_list[cho], jungsung_list[jung], jongsung_list[jong])\n",
    "\n",
    "def character_is_korean(c):\n",
    "    i = ord(c)\n",
    "    return ((kor_begin <= i <= kor_end) or\n",
    "            (jaum_begin <= i <= jaum_end) or\n",
    "            (moum_begin <= i <= moum_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ㄱ', 'ㅏ', 'ㅁ')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompose('감')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'꿈'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compose('ㄲ', 'ㅜ', 'ㅁ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 초성/중성/종성 분리를 적용한 Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jamo_levenshtein(s1, s2, debug=False):\n",
    "    if len(s1) < len(s2):\n",
    "        return jamo_levenshtein(s2, s1, debug)\n",
    "\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    def substitution_cost(c1, c2):\n",
    "        if c1 == c2:\n",
    "            return 0\n",
    "        return levenshtein(decompose(c1), decompose(c2))/3\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            #문자 삽입, 제거는 동일함\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1 \n",
    "            # Changed (문자 변경 비용을 substitution_cost로 정의한 값으로 사용)\n",
    "            substitutions = previous_row[j] + substitution_cost(c1, c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "\n",
    "        if debug:\n",
    "            print(['%.3f'%v for v in current_row[1:]])\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.000', '1.000', '2.000', '3.000']\n",
      "['1.000', '0.000', '1.000', '2.000']\n",
      "['2.000', '1.000', '0.333', '1.333']\n",
      "['3.000', '2.000', '1.333', '0.333']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '아이쿠야'\n",
    "s2 = '아이쿵야'\n",
    "jamo_levenshtein(s1, s2, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d[2,2] = 0.333 이다. ‘쿠’에서 ‘쿵’으로 변하는 비용이 0.333 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 처음부터 초/중/종성을 모두 분해하여 그대로 Levenshtein distance를 적용해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅇㅏ ㅇㅣ ㅋㅜ ㅇㅑ \n",
      "ㅇㅏ ㅇㅣ ㅋㅜㅇㅇㅑ \n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "s1 = '아이쿠야'\n",
    "s2 = '아이쿵야'\n",
    "\n",
    "s1_ = ''.join([comp for c in s1 for comp in decompose(c)])\n",
    "s2_ = ''.join([comp for c in s2 for comp in decompose(c)])\n",
    "\n",
    "print(s1_) # ㅇㅏ ㅇㅣ ㅋㅜ ㅇㅑ \n",
    "print(s2_) # ㅇㅏ ㅇㅣ ㅋㅜㅇㅇㅑ \n",
    "print(levenshtein(s1_, s2_)/3) # 0.3333333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅇㅏ ㅇㅣ ㅋㅜㅇㅇㅑ \n",
      "ㅎㅜㄺㅇㅏㅋㅇㅣ ㅋㅜ ㅇㅑ \n",
      "1.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "s1 = '아이쿵야'\n",
    "s2 = '훍앜이쿠야'\n",
    "\n",
    "s1_ = ''.join([comp for c in s1 for comp in decompose(c)])\n",
    "s2_ = ''.join([comp for c in s2 for comp in decompose(c)])\n",
    "\n",
    "print(s1_) # ㅇㅏ ㅇㅣ ㅋㅜㅇㅇㅑ \n",
    "print(s2_) # ㅎㅜㄺㅇㅏㅋㅇㅣ ㅋㅜ ㅇㅑ \n",
    "print(levenshtein(s1_, s2_)/3) # 1.6666666666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## soynlp 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from soynlp.hangle import levenshtein\n",
    "from soynlp.hangle import jamo_levenshtein\n",
    "\n",
    "s1 = '아이쿠야'\n",
    "s2 = '아이쿵야'\n",
    "\n",
    "print(levenshtein(s1, s2)) # 1\n",
    "print(jamo_levenshtein(s1, s2)) # 0.3333333333333333"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
